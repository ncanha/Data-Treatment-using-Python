{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to download multiple files from a webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to where download the data and enter in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check which is the folder you are on using \"pwd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nuno Canha\\\\Desktop\\\\Python\\\\Geo\\\\Notebooks'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a folder to where download the data and enter in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuno Canha\\Desktop\\Python\\Weather\\Raw data\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Nuno Canha\\Desktop\\Python\\Weather\\Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nuno Canha\\\\Desktop\\\\Python\\\\Weather\\\\Raw data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to install two packages \"Beautiful Soup 4\" and \"requests\"\n",
    "# pip install requests\n",
    "# pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking into account the example of PROMICE weather data to download, such as in the following webpage: http://promice.org/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is necessary to create a scheme so all files in the webpage are downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, define the webpage domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"http://promice.org/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to get the page, so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"http://promice.org/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we want to get the html from that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = page.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we are going to use \"Beautiful Soup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this moment, we have all html in a variable. Now we just get the links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/CEN_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/EGP_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/KAN_B_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/KAN_L_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/KAN_M_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/KAN_U_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/KPC_L_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/KPC_U_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/MIT_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/NUK_K_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/NUK_L_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/NUK_N_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/NUK_U_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/QAS_A_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/QAS_L_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/QAS_M_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/QAS_U_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/SCO_L_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/SCO_U_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/TAS_A_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/TAS_L_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/TAS_U_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/THU_L_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/THU_U_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/UPE_L_transmitted.csv\n",
      "/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/transmitted/UPE_U_transmitted.csv\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    url = link.get('href')\n",
    "    # now we need to add the conditions to the target files to download (e.g.: csv, txt)\n",
    "    if \".csv\" in url:\n",
    "        print(url)\n",
    "    # To define the filenames using the filenames in the link of the files\n",
    "        file_name = url.split(\"transmitted/\",1)[1]\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            response = get(domain + url)\n",
    "            file.write(response.content)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All files are download in the defined folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
